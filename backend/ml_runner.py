"""
ML Runner - Implements the 3-Step Pipeline:
1. CAT12 Preprocessing -> mwp1 file
2. Slice Extraction -> 5 images
3. Model Inference -> Prediction
"""

import logging
import time
import os
import numpy as np
from typing import Dict, Any

from config import (
    USE_MOCK_MODEL, ANALYSIS_TYPES, 
    USE_CAT12_PREPROCESSING, CONVIT_CHECKPOINT_PATH,
    NORMATIVE_VOLUMES
)
from cat12_manager import run_cat12_preprocessing

logger = logging.getLogger(__name__)

# =============================================================================
# PIPELINE IMPLEMENTATION
# =============================================================================

def run_model(scan_path: str, analysis_type: str = 'multi-disease') -> Dict[str, Any]:
    # Check if mock mode is enabled
    if USE_MOCK_MODEL:
        try:
            from ml_runner_mock import _run_model_mock
            return _run_model_mock(scan_path, analysis_type)
        except ImportError:
            pass

    start_time = time.time()
    
    # --- Step 1: Preprocessing (CAT12) ---
    processed_path = scan_path
    used_cat12 = False
    
    if USE_CAT12_PREPROCESSING:
        logger.info("STEP 1: Starting CAT12 Preprocessing...")
        
        # Check if already processed
        if "mwp1" in os.path.basename(scan_path):
             logger.info("Input file appears to be mwp1 already. Skipping CAT12.")
             processed_path = scan_path
             used_cat12 = True
        else:
            mwp1_file = run_cat12_preprocessing(scan_path)
            if mwp1_file and os.path.exists(mwp1_file):
                processed_path = mwp1_file
                used_cat12 = True
                logger.info(f"STEP 1 COMPLETE: Generated {mwp1_file}")
            else:
                logger.warning("STEP 1 FAILED: Could not generate mwp1 file. Proceeding with raw scan.")

    # --- Step 2: Slice Extraction ---
    logger.info("STEP 2: Extracting 5 slices...")
    slice_paths = []
    
    try:
        # [FIX] Import the Class, NOT 'quick_slice'
        from ml.nifti_slicer import NIfTISlicer
        
        # Prepare output directory
        slice_dir = os.path.join(os.path.dirname(processed_path), "slices")
        os.makedirs(slice_dir, exist_ok=True)
        
        # Initialize Slicer
        slicer = NIfTISlicer(output_format='png', normalize=True)
        
        # Extract Slices (Using the NEW method)
        slice_paths = slicer.extract_middle_slices(
            nifti_path=str(processed_path), 
            num_slices=5, 
            output_dir=slice_dir,
            view_plane='axial'
        )
        
        if not slice_paths:
            raise ValueError("Slicer returned no images.")
            
        logger.info(f"STEP 2 COMPLETE: Extracted {len(slice_paths)} slices.")
        
    except Exception as e:
        logger.error(f"STEP 2 ERROR: {e}")
        return _error_response(f"Slice extraction failed: {str(e)}")

    # --- Step 3: Model Inference ---
    logger.info("STEP 3: Running Model on Slices...")
    prediction_result = {}

    try:
        from ml.predictor import create_predictor

        if not os.path.exists(CONVIT_CHECKPOINT_PATH):
            logger.warning(f"Model checkpoint not found: {CONVIT_CHECKPOINT_PATH}")
            logger.warning("Falling back to mock predictions.")
            from ml_runner_mock import _run_model_mock
            return _run_model_mock(scan_path, analysis_type)

        predictor = create_predictor(CONVIT_CHECKPOINT_PATH)

        if not predictor.is_available():
            logger.warning("Model failed to initialize. Falling back to mock predictions.")
            from ml_runner_mock import _run_model_mock
            return _run_model_mock(scan_path, analysis_type)

        prediction_result = predictor.predict_patient(slice_paths)

        logger.info(f"STEP 3 COMPLETE: Diagnosis {prediction_result['patient_diagnosis']}")

    except Exception as e:
        logger.error(f"STEP 3 ERROR: {e}")
        logger.warning("Falling back to mock predictions.")
        try:
            from ml_runner_mock import _run_model_mock
            return _run_model_mock(scan_path, analysis_type)
        except Exception:
            return _error_response(f"Model inference failed: {str(e)}")

    # --- Formatting Response ---
    classes = ANALYSIS_TYPES.get(analysis_type, ['CN', 'MCI', 'AD'])
    predicted_label = prediction_result.get('patient_diagnosis', 'Unknown')
    confidence = prediction_result.get('confidence', 0.0) / 100.0
    
    probabilities = [0.0] * len(classes)
    if predicted_label in classes:
        idx = classes.index(predicted_label)
        probabilities[idx] = confidence
        remainder = (1.0 - confidence) / (len(classes) - 1) if len(classes) > 1 else 0
        for i in range(len(classes)):
            if i != idx: probabilities[i] = remainder

    # Extract real volumes from mwp1/mwp2 if available, fallback to estimates
    if 'mwp1' in os.path.basename(processed_path):
        try:
            from volumetric_analyzer import extract_volumes_from_nifti
            mwp2_path = processed_path.replace('mwp1', 'mwp2')
            if not os.path.exists(mwp2_path):
                mwp2_path = None
            volumes = extract_volumes_from_nifti(processed_path, mwp2_path)
            logger.info(f"Real volumes extracted from NIfTI: GM={volumes['gm']}, WM={volumes['wm']}")
        except Exception as e:
            logger.warning(f"Real volume extraction failed: {e}, using estimates")
            volumes = _generate_consistent_volumes(predicted_label)
    else:
        volumes = _generate_consistent_volumes(predicted_label)

    return {
        'prediction': predicted_label,
        'confidence': confidence,
        'probabilities': probabilities,
        'classes': classes,
        'brain_volume': volumes['brain'],
        'gm_volume': volumes['gm'],
        'wm_volume': volumes['wm'],
        'csf_volume': volumes['csf'],
        'hippocampal_volume': volumes['hippo'],
        'ventricular_volume': volumes['ventricles'],
        'processing_time': int((time.time() - start_time) * 1000),
        'analysis_type': analysis_type,
        'used_cat12': used_cat12,
        'model_version': 'ConViT-v1.0',
        'status': 'success'
    }

def get_volume_comparison(ml_results: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:
    """Compare measured volumes with normative ranges."""
    comparisons = {}
    volume_mappings = {
        'total_brain': ('brain_volume', NORMATIVE_VOLUMES['total_brain']),
        'gray_matter': ('gm_volume', NORMATIVE_VOLUMES['gray_matter']),
        'white_matter': ('wm_volume', NORMATIVE_VOLUMES['white_matter']),
        'csf': ('csf_volume', NORMATIVE_VOLUMES['csf']),
        'hippocampus': ('hippocampal_volume', NORMATIVE_VOLUMES['hippocampus']),
    }
    for name, (key, norm) in volume_mappings.items():
        value = ml_results.get(key)
        if value is not None:
            if value < norm['min']:
                status = 'Below Normal'
                deviation = ((norm['min'] - value) / norm['min']) * 100
            elif value > norm['max']:
                status = 'Above Normal'
                deviation = ((value - norm['max']) / norm['max']) * 100
            else:
                status = 'Normal'
                mid = (norm['min'] + norm['max']) / 2
                deviation = ((value - mid) / mid) * 100
            comparisons[name] = {
                'measured': value, 'min_normal': norm['min'], 'max_normal': norm['max'],
                'unit': norm['unit'], 'status': status, 'deviation_percent': round(abs(deviation), 1)
            }
    return comparisons

def _error_response(msg):
    return {
        'prediction': 'Error', 'confidence': 0.0, 'probabilities': [0, 0, 0],
        'classes': ['Error'], 'brain_volume': 0, 'processing_time': 0, 'error_details': msg
    }

def _generate_consistent_volumes(label):
    base = 1300
    if label == 'AD': factor = 0.85
    elif label == 'MCI': factor = 0.92
    else: factor = 1.0
    return {
        'brain': base * factor, 'gm': base * 0.45 * factor, 'wm': base * 0.40 * factor,
        'csf': base * 0.15 * (2 - factor), 'hippo': 4.0 * factor, 'ventricles': 30.0 * (2 - factor)
    }